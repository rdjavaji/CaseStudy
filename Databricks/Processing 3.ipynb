{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a233a83-4ba1-44fe-b004-1b705568617b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "\"fs.azure.account.key.myrgstore.dfs.core.windows.net\",\n",
    "\"Cdhaz7zz+7n6gOYQq7TH36+rB8P+5HMV5yf=====================================\")\n",
    "\n",
    "# Read Data from Silver Container:\n",
    "accounts_df = spark.read.format(\"delta\").load(\"abfss://silver@myrgstore.dfs.core.windows.net/delta/accounts_delta\")\n",
    "customers_df = spark.read.format(\"delta\").load(\"abfss://silver@myrgstore.dfs.core.windows.net/delta/customers_delta\")\n",
    "loan_payments_df = spark.read.format(\"delta\").load(\"abfss://silver@myrgstore.dfs.core.windows.net/delta/loan_payments_delta\")\n",
    "loans_df = spark.read.format(\"delta\").load(\"abfss://silver@myrgstore.dfs.core.windows.net/delta/loans_delta\")\n",
    "transactions_df = spark.read.format(\"delta\").load(\"abfss://silver@myrgstore.dfs.core.windows.net/delta/transactions_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "100838cc-0329-4e89-85ee-7b827061b385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n== Parsed Logical Plan ==\n'Aggregate ['account_id], ['account_id, 'sum('transaction_amount) AS total_transactions#7012]\n+- RepartitionByExpression [account_id#6976], 10\n   +- Relation [transaction_id#6975,account_id#6976,transaction_date#6977,transaction_amount#6978,transaction_type#6979] parquet\n\n== Analyzed Logical Plan ==\naccount_id: int, total_transactions: double\nAggregate [account_id#6976], [account_id#6976, sum(transaction_amount#6978) AS total_transactions#7012]\n+- RepartitionByExpression [account_id#6976], 10\n   +- Relation [transaction_id#6975,account_id#6976,transaction_date#6977,transaction_amount#6978,transaction_type#6979] parquet\n\n== Optimized Logical Plan ==\nAggregate [account_id#6976], [account_id#6976, sum(transaction_amount#6978) AS total_transactions#7012]\n+- RepartitionByExpression [account_id#6976], 10\n   +- Project [account_id#6976, transaction_amount#6978]\n      +- Relation [transaction_id#6975,account_id#6976,transaction_date#6977,transaction_amount#6978,transaction_type#6979] parquet\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- == Initial Plan ==\n   ColumnarToRow\n   +- PhotonResultStage\n      +- PhotonGroupingAgg(limit=None, keys=[account_id#6976], functions=[sum(transaction_amount#6978)], output=[account_id#6976, total_transactions#7012])\n         +- PhotonShuffleExchangeSource\n            +- PhotonShuffleMapStage\n               +- PhotonShuffleExchangeSink hashpartitioning(account_id#6976, 10)\n                  +- PhotonScan parquet [account_id#6976,transaction_amount#6978] DataFilters: [], DictionaryFilters: [], Format: parquet, Location: PreparedDeltaFileIndex(1 paths)[abfss://silver@myrgstore.dfs.core.windows.net/delta/transactions_..., OptionalDataFilters: [], PartitionFilters: [], ReadSchema: struct<account_id:int,transaction_amount:double>, RequiredDataFilters: []\n\n== Photon Explanation ==\nThe query is fully supported by Photon.\n"
     ]
    }
   ],
   "source": [
    "# TROUBLESHOOT PARTITION Data Shuffling with groupBy()\n",
    "\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "\n",
    "# Example of a `groupBy()` operation in PySpark\n",
    "transactions_grouped = transactions_df.groupBy(\"account_id\").agg(\n",
    "    _sum(\"transaction_amount\").alias(\"total_transactions\")\n",
    ")\n",
    "\n",
    "# Check the current number of partitions\n",
    "print(transactions_df.rdd.getNumPartitions())\n",
    "\n",
    "# Repartition data by `account_id` to minimize shuffling\n",
    "transactions_repartitioned = transactions_df.repartition(10, \"account_id\")\n",
    "\n",
    "# Perform the GroupBy and Aggregation\n",
    "transactions_grouped = transactions_repartitioned.groupBy(\"account_id\").agg(\n",
    "    _sum(\"transaction_amount\").alias(\"total_transactions\")\n",
    ")\n",
    "\n",
    "display(transactions_grouped.explain(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6400b8e8-a7ff-4ffe-9d44-f9822fb757f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>account_id</th><th>total_transaction_amount</th></tr></thead><tbody><tr><td>1</td><td>100.0</td></tr><tr><td>6</td><td>-300.0</td></tr><tr><td>3</td><td>150.0</td></tr><tr><td>5</td><td>250.0</td></tr><tr><td>4</td><td>-200.0</td></tr><tr><td>8</td><td>-150.0</td></tr><tr><td>7</td><td>400.0</td></tr><tr><td>2</td><td>250.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         100.0
        ],
        [
         6,
         -300.0
        ],
        [
         3,
         150.0
        ],
        [
         5,
         250.0
        ],
        [
         4,
         -200.0
        ],
        [
         8,
         -150.0
        ],
        [
         7,
         400.0
        ],
        [
         2,
         250.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "account_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "total_transaction_amount",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Identify Data Skew - group transactions by account_id and calculate the total transaction amount for each customer. As customers have many more transactions than others, this result in a skewed dataset.\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "transactions_grouped = transactions_df.groupBy(\"account_id\").agg(\n",
    "    sum(\"transaction_amount\").alias(\"total_transaction_amount\")\n",
    ")\n",
    "display(transactions_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c62cecd0-095f-48ba-9ef8-4481cca5d347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>salted_account_id</th><th>total_transaction_amount</th></tr></thead><tbody><tr><td>4</td><td>150.0</td></tr><tr><td>10</td><td>700.0</td></tr><tr><td>11</td><td>-50.0</td></tr><tr><td>8</td><td>450.0</td></tr><tr><td>15</td><td>-300.0</td></tr><tr><td>9</td><td>-250.0</td></tr><tr><td>6</td><td>-200.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4,
         150.0
        ],
        [
         10,
         700.0
        ],
        [
         11,
         -50.0
        ],
        [
         8,
         450.0
        ],
        [
         15,
         -300.0
        ],
        [
         9,
         -250.0
        ],
        [
         6,
         -200.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "salted_account_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "total_transaction_amount",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Salting \n",
    "\n",
    "from pyspark.sql.functions import col, rand, sum\n",
    "\n",
    "# Step 1: Add a random number (salt) to the account_id\n",
    "salted_transactions_df = transactions_df.withColumn(\n",
    "    \"salted_account_id\", \n",
    "    (col(\"account_id\") + (rand() * 10).cast(\"int\"))  # Adding random number between 0 and 9\n",
    ")\n",
    "\n",
    "# Step 2: Repartition the DataFrame based on the salted account_id\n",
    "salted_transactions_repartitioned = salted_transactions_df.repartition(10, \"salted_account_id\")\n",
    "\n",
    "# Verify the number of partitions\n",
    "print(salted_transactions_repartitioned.rdd.getNumPartitions())\n",
    "\n",
    "# Step 3: Perform aggregation after salting (example: summing transactions per account_id)\n",
    "transactions_grouped_salted = salted_transactions_repartitioned.groupBy(\"salted_account_id\").agg(\n",
    "    sum(\"transaction_amount\").alias(\"total_transaction_amount\")\n",
    ")\n",
    "\n",
    "display(transactions_grouped_salted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "067e6d03-3ef6-4cf5-a797-e72ba288a4ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>transaction_id</th><th>account_id</th><th>transaction_date</th><th>transaction_amount</th><th>transaction_type</th><th>salted_customer_id</th><th>customer_id</th><th>first_name</th><th>last_name</th><th>address</th><th>city</th><th>state</th><th>postal_code</th><th>salted_customer_id</th></tr></thead><tbody><tr><td>7</td><td>5</td><td>2024-09-07</td><td>250.0</td><td>Deposit</td><td>14</td><td>9</td><td>Olivia</td><td>Davis</td><td>606 Fir St</td><td>Boston</td><td>MA</td><td>2101</td><td>14</td></tr><tr><td>3</td><td>2</td><td>2024-09-02</td><td>300.0</td><td>Deposit</td><td>6</td><td>6</td><td>David</td><td>Jones</td><td>303 Cedar St</td><td>Los Angeles</td><td>CA</td><td>90001</td><td>6</td></tr><tr><td>5</td><td>3</td><td>2024-09-05</td><td>150.0</td><td>Deposit</td><td>5</td><td>2</td><td>Jane</td><td>Smith</td><td>456 Oak St</td><td>Chicago</td><td>IL</td><td>60614</td><td>5</td></tr><tr><td>7</td><td>5</td><td>2024-09-07</td><td>250.0</td><td>Deposit</td><td>14</td><td>7</td><td>Laura</td><td>Garcia</td><td>404 Willow St</td><td>San Francisco</td><td>CA</td><td>94101</td><td>14</td></tr><tr><td>6</td><td>4</td><td>2024-09-06</td><td>-200.0</td><td>Withdrawal</td><td>4</td><td>4</td><td>Michael</td><td>Williams</td><td>101 Maple St</td><td>Seattle</td><td>WA</td><td>98101</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         7,
         5,
         "2024-09-07",
         250.0,
         "Deposit",
         14,
         9,
         "Olivia",
         "Davis",
         "606 Fir St",
         "Boston",
         "MA",
         2101,
         14
        ],
        [
         3,
         2,
         "2024-09-02",
         300.0,
         "Deposit",
         6,
         6,
         "David",
         "Jones",
         "303 Cedar St",
         "Los Angeles",
         "CA",
         90001,
         6
        ],
        [
         5,
         3,
         "2024-09-05",
         150.0,
         "Deposit",
         5,
         2,
         "Jane",
         "Smith",
         "456 Oak St",
         "Chicago",
         "IL",
         60614,
         5
        ],
        [
         7,
         5,
         "2024-09-07",
         250.0,
         "Deposit",
         14,
         7,
         "Laura",
         "Garcia",
         "404 Willow St",
         "San Francisco",
         "CA",
         94101,
         14
        ],
        [
         6,
         4,
         "2024-09-06",
         -200.0,
         "Withdrawal",
         4,
         4,
         "Michael",
         "Williams",
         "101 Maple St",
         "Seattle",
         "WA",
         98101,
         4
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "transaction_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "account_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "transaction_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "transaction_amount",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "transaction_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salted_customer_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "postal_code",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "salted_customer_id",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join Tables Using Salted Keys\n",
    "from pyspark.sql.functions import col, rand\n",
    "\n",
    "# Salt the customers DataFrame\n",
    "salted_customers_df = customers_df.withColumn(\n",
    "    \"salted_customer_id\", \n",
    "    (col(\"customer_id\") + (rand() * 10).cast(\"int\"))\n",
    ")\n",
    "\n",
    "# Salt the transactions DataFrame using the correct column name\n",
    "salted_transactions_repartitioned = transactions_df.withColumn(\n",
    "    \"salted_customer_id\", \n",
    "    (col(\"account_id\") + (rand() * 10).cast(\"int\"))\n",
    ")\n",
    "\n",
    "# Perform the join using the salted_customer_id\n",
    "joined_df = salted_transactions_repartitioned.join(\n",
    "    salted_customers_df, \n",
    "    salted_transactions_repartitioned[\"salted_customer_id\"] == salted_customers_df[\"salted_customer_id\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Show the results of the join\n",
    "display(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be44a7dc-69b5-4624-8a44-28ddb78f89f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+------------------+----------------+------------------+-----------+----------+---------+-------------+-------------+-----+-----------+------------------+\n|transaction_id|account_id|transaction_date|transaction_amount|transaction_type|salted_customer_id|customer_id|first_name|last_name|address      |city         |state|postal_code|salted_customer_id|\n+--------------+----------+----------------+------------------+----------------+------------------+-----------+----------+---------+-------------+-------------+-----+-----------+------------------+\n|7             |5         |2024-09-07      |250.0             |Deposit         |14                |9          |Olivia    |Davis    |606 Fir St   |Boston       |MA   |2101       |14                |\n|3             |2         |2024-09-02      |300.0             |Deposit         |6                 |6          |David     |Jones    |303 Cedar St |Los Angeles  |CA   |90001      |6                 |\n|5             |3         |2024-09-05      |150.0             |Deposit         |5                 |2          |Jane      |Smith    |456 Oak St   |Chicago      |IL   |60614      |5                 |\n|7             |5         |2024-09-07      |250.0             |Deposit         |14                |7          |Laura     |Garcia   |404 Willow St|San Francisco|CA   |94101      |14                |\n|6             |4         |2024-09-06      |-200.0            |Withdrawal      |4                 |4          |Michael   |Williams |101 Maple St |Seattle      |WA   |98101      |4                 |\n+--------------+----------+----------------+------------------+----------------+------------------+-----------+----------+---------+-------------+-------------+-----+-----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "joined_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc362af2-c867-4f9f-b58d-986f98f3a1d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicate columns\n",
    "\n",
    "joined_df = joined_df.toDF(*(col if col not in joined_df.columns[:i] else f\"{col}_duplicate\" for i, col in enumerate(joined_df.columns)))\n",
    "\n",
    "# Define the path for gold container\n",
    "\n",
    "gold_delta = \"abfss://gold@myrgstore.dfs.core.windows.net/delta/gold_delta\"\n",
    "\n",
    "# Save the DataFrame in Delta format, overwriting if it exists\n",
    "\n",
    "joined_df.write.format(\"delta\").mode(\"overwrite\").save(gold_delta)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Processing 3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
